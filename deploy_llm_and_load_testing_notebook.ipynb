{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c4d5506-8de7-433b-a8a8-97341f59a422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::555043101106:role/Weka-Test-Stack-SageMakerExecutionRole-19XRWUDUCV474\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "    \n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "#\t'HF_MODEL_ID':'meta-llama/Meta-Llama-3-8B',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "\t'HUGGING_FACE_HUB_TOKEN': '<your HF token>'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8eb50f8d-e32d-4902-b02e-5295d718f12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4.2\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df7e2422-dbb4-4fdd-a231-de08a0ff2261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "llm = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.48xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "508300da-ecb4-4ae5-941f-50943106ee5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"My name is Julien and I like to spend time outside, walking in the mountains or cycling through the fields. I love photography, especially landscape and nature, capturing the beauty of the world around us. When I'm not out doors, I enjoy working in my home studio, experimenting with new techniques and styles. I also love music and spending time with friends and family.\"}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send request\n",
    "llm.predict({\n",
    "\t\"inputs\": \"My name is Julien and I like to\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6a63ce7-c7c8-4bcb-a5c0-4e6ca6c78377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2024-05-10-13-15-48-841'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b084c07-7e5a-4f79-86d6-bebfd7770aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42946df3-1105-4101-a470-15fcfaa6a899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b5d4c4-d7c8-419b-b465-f98cd9be06df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "Successfully installed huggingface_hub-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66d3a0c7-95ed-4049-b58e-8cfa5c73d471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30a7ae152224cadb84cd1cb4821a379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1f6c85b-d3d1-425c-b632-ab7e774f2d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3eaef07b8234611899a4df4328075c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e97b76624247309fc5606e1e276351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c0c5d56dc54494b162aa350b21551f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac30feb76424b18a9918279116e77bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-70b-chat-hf\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f6725-bd3a-4f86-9237-e1222ff6663e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a4629ac-f068-4425-82df-4d7f89e67f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import json\n",
    " \n",
    "sys.path.append(\"utils\")\n",
    "from get_metrics import get_metrics_from_cloudwatch\n",
    " \n",
    "# Generation arguments\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.6,\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_new_tokens\": 250,\n",
    "    \"return_full_text\": False,\n",
    "}\n",
    " \n",
    "# The function to perform a single request\n",
    "def make_request(payload):\n",
    "    try:\n",
    "        llm.predict(\n",
    "            data={\n",
    "                \"inputs\": tokenizer.apply_chat_template(\n",
    "                    [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": payload\n",
    "                        }\n",
    "                    ],\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True,\n",
    "                ),\n",
    "                \"parameters\": parameters,\n",
    "            }\n",
    "        )\n",
    "        return 200\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 500\n",
    "    \n",
    "# Main function to run the load test\n",
    "def run_load_test(total_requests, concurrent_users):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:\n",
    "        # Prepare a list of the same inputs to hit multiple times\n",
    "        tasks = [\"Write a long story about llamas and why should protect them.\"] * total_requests\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # run the requests\n",
    "        results = list(tqdm(executor.map(make_request, tasks), total=total_requests, desc=\"Running load test\"))\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"Total time for {total_requests} requests with {concurrent_users} concurrent users: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Successful rate: {results.count(200) / total_requests * 100:.2f}%\")\n",
    "        # Get the metrics\n",
    "        metrics = get_metrics_from_cloudwatch(\n",
    "            endpoint_name=llm.endpoint_name,\n",
    "            st=int(start_time),\n",
    "            et=int(end_time),\n",
    "            cu=concurrent_users,\n",
    "            total_requests=total_requests,\n",
    "            boto3_session=sess.boto_session\n",
    "        )\n",
    "        # store results\n",
    "        with open(\"results.json\", \"w\") as f:\n",
    "            json.dump(metrics, f)\n",
    "        # print results\n",
    "        # print(f\"Llama 3 8B results on `g5.2xlarge`:\")\n",
    "        print(f\"Mistral 7B Instruct results on `g5.48xlarge`:\")\n",
    "        print(f\"Throughput: {metrics['Thorughput (tokens/second)']:,.2f} tokens/s\")\n",
    "        print(f\"Latency p(50): {metrics['Latency (ms/token) p(50)']:,.2f} ms/token\")\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52d3c0-9ccc-4a35-8aa0-80ab6e63b491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb66a5d3-4bde-4907-9849-7213c0530e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running load test: 100%|██████████| 100/100 [02:58<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 100 requests with 5 concurrent users: 178.85 seconds\n",
      "Successful rate: 100.00%\n",
      "Waiting for logs to be available ...\n",
      "Waiting for query to complete ...\n",
      "Waiting for query to complete ...\n",
      "Waiting for query to complete ...\n",
      "Mistral 7B Instruct results on `g5.48xlarge`:\n",
      "Throughput: 139.66 tokens/s\n",
      "Latency p(50): 35.47 ms/token\n"
     ]
    }
   ],
   "source": [
    "# Run the load test\n",
    "concurrent_users = 5\n",
    "number_of_requests = 100\n",
    "res = run_load_test(number_of_requests, concurrent_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76fae5-6af9-448d-af2d-23460367ffa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb11b4-71d8-4f16-9e9a-dfa53c003910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b6d2a-1c36-4f72-a900-05e448e25edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
